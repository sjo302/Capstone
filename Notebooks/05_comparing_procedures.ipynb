{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', 400)\n",
    "pd.set_option('display.max_columns', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions from helper_functions.py (couldn't import for some reason)\n",
    "\n",
    "def set_nulls(data):\n",
    "    \"\"\"\n",
    "   @param data: dataframe\n",
    "   \n",
    "   @return dataframe with -99 replaced with NaN\n",
    "    \"\"\"\n",
    "    data.replace(to_replace = -99, value = np.nan)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def map_cpt(data, column, replace, name):\n",
    "    \"\"\"\n",
    "    @param data: dataframe\n",
    "    @param column: string, column name\n",
    "    @param replace: list of variables holding the values to be replaced by that particular variable name\n",
    "    @ param name: string or integer of what will replace the values in replacements\n",
    "\n",
    "    \"\"\"\n",
    "    for r in replace:\n",
    "        idx = np.where(data[column] == r)[0]\n",
    "        data[column].loc[idx] = name\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\preston\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1637: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('../data/monet_output.csv')\n",
    "data.drop(['Unnamed: 0', 'X'], axis = 1, inplace = True)\n",
    "integer_cols = data.dtypes == int\n",
    "int_cols = data.columns[integer_cols]\n",
    "df = set_nulls(data)\n",
    "float_flag = df.dtypes == float\n",
    "float_cols = df.columns[float_flag]\n",
    "\n",
    "op1 = ['COLCT TOT ABDL W/O PRCTECT W/CONTINENT ILEOST']\n",
    "op2 = ['COLCT TOT ABDL W/O PRCTECT W/ILEOST/ILEOPXTS', 'LAPS COLECTOMY TOT W/O PRCTECT W/ILEOST/ILEOPXTS']\n",
    "op3 = ['COLECTOMY PARTIAL W/ANASTOMOSIS', 'LAPAROSCOPY COLECTOMY PARTIAL W/ANASTOMOSIS']\n",
    "op4 = ['COLECTOMY PRTL ABDOMINAL & TRANSANAL APPROACH', 'COLECTOMY PRTL ABDOMINAL & TRANSANAL APPR']\n",
    "op5 = ['COLECTOMY PRTL W/COLOPROCTOSTOMY', 'LAPS COLECTOMY PRTL W/COLOPXTSTMY LW ANAST']\n",
    "op6 = ['COLECTOMY PRTL W/COLOPROCTOSTOMY & COLOSTOMY', 'LAPS COLECTMY PRTL W/COLOPXTSTMY LW ANAST W/CLST']\n",
    "op7 = ['COLECTOMY PRTL W/COLOST/ILEOST & MUCOFISTULA']\n",
    "op8 = ['COLECTOMY PRTL W/END COLOSTOMY & CLSR DSTL SGMT', 'COLECTOMY PRTL W/END COLOSTOMY&CLSR DSTL SGMT', 'LAPS COLECTOMY PRTL W/END CLST & CLSR DSTL SGM', 'LAPS COLECTOMY PRTL W/END CLST&CLSR DSTL SGM']\n",
    "op9 = ['COLECTOMY PRTL W/RMVL TERMINAL ILEUM & ILEOCOLOS', 'COLECTOMY PRTL W/RMVL TERMINAL ILEUM&ILEOCOLOST', 'LAPS COLECTOMY PRTL W/RMVL TERMINAL ILEUM', 'COLECTOMY PRTL W/RMVL TERMINAL ILEUM & ILEOCOLOST']\n",
    "op10 = ['COLECTOMY PRTL W/SKIN LEVEL CECOST/COLOSTOMY']\n",
    "num_replacements = [op1, op2, op3, op4, op5, op6, op7, op8, op9, op10]\n",
    "for i in range(len(num_replacements)):\n",
    "    df_clean = map_cpt(df, 'PRNCPTX', num_replacements[i], i+1)\n",
    "\n",
    "MIS = ['Laparoscopic', 'Endoscopic w/ unplanned conversion to open', 'Hybrid', 'Hybrid w/ open assist', 'Laparoscopic Hand Assisted', 'Laparoscopic w/ open assist', 'Laparoscopic w/ unplanned conversion to open', 'Laparoscopic w/ unplanned conversion to Open', 'Other MIS approach', 'Robotic', 'Robotic w/ open assist', 'Robotic w/ unplanned conversion to open', 'SILS', 'SILS w/ open assist', 'SILS w/ unplanned conversion to open', 'Hybrid w/ unplanned conversion to open', 'Endoscopic w/ open assist', 'Other MIS approach w/ open assist', 'Endoscopic', 'NOTES', 'NOTES w/ open assist', 'Other MIS approach w/ unplanned conversion to open', 'NOTES w/ unplanned conversion to open']\n",
    "Open = ['Open', 'Open (planned)']\n",
    "options = [MIS, Open]\n",
    "names = ['MIS', 'open']\n",
    "for i in range(len(options)):\n",
    "    df_clean = map_cpt(df_clean, 'COL_APPROACH', options[i], names[i])\n",
    "\n",
    "#convert unknowns to NAs\n",
    "nulls = np.where(df_clean.COL_APPROACH == 'Unknown')[0]\n",
    "df_clean.COL_APPROACH.loc[nulls] = np.nan\n",
    "\n",
    "unplanned = [c for c in df_clean if \"UNPLANNEDREADMISSION\" in c]\n",
    "df_clean['num_unplanned'] = df_clean[unplanned].sum(axis=1)\n",
    "df_clean['target'] = [1 if x>0 else 0 for x in df_clean['num_unplanned']]\n",
    "\n",
    "othercpt = [c for c in df_clean if \"OTHERCPT\" in c]\n",
    "df_clean['num_other_procs'] = df_clean[othercpt].count(axis=1)\n",
    "concurrcpt = [c for c in df_clean if \"CONCURR\" in c]\n",
    "df_clean['num_concurr_procs'] = df_clean[concurrcpt].count(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing procedure types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------\n",
      "OTHERPROC\n",
      "----------\n",
      "             unique_vals  proportion\n",
      "OTHERPROC1          1087    0.505806\n",
      "OTHERPROC2           970    0.213805\n",
      "OTHERPROC3           764    0.080899\n",
      "OTHERPROC4           595    0.029502\n",
      "OTHERPROC5           405    0.010837\n",
      "OTHERPROC6           271    0.003982\n",
      "OTHERPROC7           177    0.001644\n",
      "OTHERPROC8           129    0.000768\n",
      "OTHERPROC9            62    0.000341\n",
      "OTHERPROC10           32    0.000171\n",
      "\n",
      "The total number of unique procedures is 1603 \n",
      "\n",
      "89 observations have 'out of order' procedures\n",
      "\n",
      "\n",
      "----------\n",
      "CONCURR\n",
      "----------\n",
      "           unique_vals  proportion\n",
      "CONCURR1          1105    0.139733\n",
      "CONCURR2           776    0.039397\n",
      "CONCURR3           525    0.009654\n",
      "CONCURR4           267    0.003133\n",
      "CONCURR5           147    0.001198\n",
      "CONCURR6            84    0.000492\n",
      "CONCURR7            43    0.000229\n",
      "CONCURR8            22    0.000124\n",
      "CONCURR9            10    0.000066\n",
      "CONCURR10            7    0.000050\n",
      "\n",
      "The total number of unique procedures is 1617 \n",
      "\n",
      "8 observations have 'out of order' procedures\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Check procedures within OTHERPROC\n",
    "procvec = [\"OTHERPROC\", \"CONCURR\"]\n",
    "\n",
    "for proctype in procvec:\n",
    "    proc = data.filter(like = proctype)\n",
    "    proc.index = data.CASEID.astype('int')\n",
    "\n",
    "    ## Get aggregate stats on OTHERPROC\n",
    "    varnames = []\n",
    "    unique_vals = []\n",
    "    proportion = []\n",
    "\n",
    "    all_procs = []\n",
    "\n",
    "    for i in range(proc.shape[1]):\n",
    "        var = proctype + str(i + 1)\n",
    "\n",
    "        varnames.append(var)\n",
    "        unique_vals.append(proc[var].nunique())\n",
    "        proportion.append(1 - (proc[var].isna().sum()/len(proc[var])))\n",
    "\n",
    "        all_procs = all_procs + proc[var].value_counts().index.tolist()\n",
    "\n",
    "    proc_stats = pd.DataFrame({\"unique_vals\":unique_vals, \"proportion\":proportion}, index = varnames)\n",
    "\n",
    "    all_procs = set(all_procs)\n",
    "\n",
    "    ## Confirm that no patient has other procedures out of order\n",
    "     # i.e. no one has OTHERPROC2 without also having OTHERPROC1\n",
    "\n",
    "    ## Number of greatest OTHERPROC\n",
    "    proc_num = proc.isna()\n",
    "\n",
    "    for col in proc_num.columns:\n",
    "        proc_num[col] = np.where(proc_num[col] == False, int(re.findall(\"[0-9]+\", col)[0]), 0)\n",
    "\n",
    "    maxproc = proc_num.max(axis = 1)\n",
    "\n",
    "    ## Number of procedures with non-null values\n",
    "    numproc = (proc.isna()==False).sum(axis = 1)\n",
    "\n",
    "    ## maxproc and numproc should be equal for each observation--they aren't\n",
    "\n",
    "\n",
    "    print(\"-\"*10 + \"\\n\" + str(proctype) + \"\\n\" + \"-\"*10)\n",
    "\n",
    "    print(proc_stats)\n",
    "    print(\"\\nThe total number of unique procedures is\", len(all_procs), \"\\n\")\n",
    "\n",
    "    print(len(proc[maxproc != numproc]), \"observations have 'out of order' procedures\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
