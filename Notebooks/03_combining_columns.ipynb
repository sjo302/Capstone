{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5aafb755-7f20-4371-bf40-791bd529e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aef5d4a7-c850-4251-bc57-55792077a88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions from helper_functions.py (couldn't import for some reason)\n",
    "\n",
    "def set_nulls(data, cols):\n",
    "    \"\"\"\n",
    "   @param data: dataframe\n",
    "   @param cols: list of column names that have -99\n",
    "   \n",
    "   @return dataframe with -99 replaced with NaN\n",
    "    \"\"\"\n",
    "    for c in cols:\n",
    "        idx = np.where(data[c] == -99)[0]\n",
    "        if len(idx) > 0:\n",
    "            data[c].loc[idx] = np.nan\n",
    "            \n",
    "    return data\n",
    "\n",
    "def map_cpt(data, column, replace, name):\n",
    "    \"\"\"\n",
    "    @param data: dataframe\n",
    "    @param column: string, column name\n",
    "    @param replace: list of variables holding the values to be replaced by that particular variable name\n",
    "    @ param name: string or integer of what will replace the values in replacements\n",
    "\n",
    "    \"\"\"\n",
    "    for r in replace:\n",
    "        idx = np.where(data[column] == r)[0]\n",
    "        data[column].loc[idx] = name\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2f1c5bc1-756e-49fc-8842-ebfdb6bd6158",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/monet_output.csv')\n",
    "data.drop(['Unnamed: 0', 'X'], axis = 1, inplace = True)\n",
    "integer_cols = data.dtypes == int\n",
    "int_cols = data.columns[integer_cols]\n",
    "df = set_nulls(data, int_cols)\n",
    "float_flag = df.dtypes == float\n",
    "float_cols = df.columns[float_flag]\n",
    "df_clean = set_nulls(df, float_cols)\n",
    "\n",
    "op1 = ['COLCT TOT ABDL W/O PRCTECT W/CONTINENT ILEOST']\n",
    "op2 = ['COLCT TOT ABDL W/O PRCTECT W/ILEOST/ILEOPXTS', 'LAPS COLECTOMY TOT W/O PRCTECT W/ILEOST/ILEOPXTS']\n",
    "op3 = ['COLECTOMY PARTIAL W/ANASTOMOSIS', 'LAPAROSCOPY COLECTOMY PARTIAL W/ANASTOMOSIS']\n",
    "op4 = ['COLECTOMY PRTL ABDOMINAL & TRANSANAL APPROACH', 'COLECTOMY PRTL ABDOMINAL & TRANSANAL APPR']\n",
    "op5 = ['COLECTOMY PRTL W/COLOPROCTOSTOMY', 'LAPS COLECTOMY PRTL W/COLOPXTSTMY LW ANAST']\n",
    "op6 = ['COLECTOMY PRTL W/COLOPROCTOSTOMY & COLOSTOMY', 'LAPS COLECTMY PRTL W/COLOPXTSTMY LW ANAST W/CLST']\n",
    "op7 = ['COLECTOMY PRTL W/COLOST/ILEOST & MUCOFISTULA']\n",
    "op8 = ['COLECTOMY PRTL W/END COLOSTOMY & CLSR DSTL SGMT', 'COLECTOMY PRTL W/END COLOSTOMY&CLSR DSTL SGMT', 'LAPS COLECTOMY PRTL W/END CLST & CLSR DSTL SGM', 'LAPS COLECTOMY PRTL W/END CLST&CLSR DSTL SGM']\n",
    "op9 = ['COLECTOMY PRTL W/RMVL TERMINAL ILEUM & ILEOCOLOS', 'COLECTOMY PRTL W/RMVL TERMINAL ILEUM&ILEOCOLOST', 'LAPS COLECTOMY PRTL W/RMVL TERMINAL ILEUM', 'COLECTOMY PRTL W/RMVL TERMINAL ILEUM & ILEOCOLOST']\n",
    "op10 = ['COLECTOMY PRTL W/SKIN LEVEL CECOST/COLOSTOMY']\n",
    "num_replacements = [op1, op2, op3, op4, op5, op6, op7, op8, op9, op10]\n",
    "for i in range(len(num_replacements)):\n",
    "    df_clean = map_cpt(df_clean, 'PRNCPTX', num_replacements[i], i+1)\n",
    "\n",
    "MIS = ['Laparoscopic', 'Endoscopic w/ unplanned conversion to open', 'Hybrid', 'Hybrid w/ open assist', 'Laparoscopic Hand Assisted', 'Laparoscopic w/ open assist', 'Laparoscopic w/ unplanned conversion to open', 'Laparoscopic w/ unplanned conversion to Open', 'Other MIS approach', 'Robotic', 'Robotic w/ open assist', 'Robotic w/ unplanned conversion to open', 'SILS', 'SILS w/ open assist', 'SILS w/ unplanned conversion to open', 'Hybrid w/ unplanned conversion to open', 'Endoscopic w/ open assist', 'Other MIS approach w/ open assist', 'Endoscopic', 'NOTES', 'NOTES w/ open assist', 'Other MIS approach w/ unplanned conversion to open', 'NOTES w/ unplanned conversion to open']\n",
    "Open = ['Open', 'Open (planned)']\n",
    "options = [MIS, Open]\n",
    "names = ['MIS', 'open']\n",
    "for i in range(len(options)):\n",
    "    df_clean = map_cpt(df_clean, 'COL_APPROACH', options[i], names[i])\n",
    "\n",
    "#convert unknowns to NAs\n",
    "nulls = np.where(df_clean.COL_APPROACH == 'Unknown')[0]\n",
    "df_clean.COL_APPROACH.loc[nulls] = np.nan\n",
    "\n",
    "unplanned = [c for c in df_clean if \"UNPLANNEDREADMISSION\" in c]\n",
    "df_clean['num_unplanned'] = df_clean[unplanned].sum(axis=1)\n",
    "df_clean['target'] = [1 if x>0 else 0 for x in df_clean['num_unplanned']]\n",
    "\n",
    "othercpt = [c for c in df_clean if \"OTHERCPT\" in c]\n",
    "df_clean['num_other_procs'] = df_clean[othercpt].count(axis=1)\n",
    "concurrcpt = [c for c in df_clean if \"CONCURR\" in c]\n",
    "df_clean['num_concurr_procs'] = df_clean[concurrcpt].count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "294fcca9-57a4-4b1a-8504-93c032b75ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/data_cleaning.json',)\n",
    "clean_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fd655246-5ced-4925-a393-379c36b0e8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = clean_dict['cols_to_drop']\n",
    "df_clean.drop(columns=cols_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dc3a4da2-6621-4804-89e4-2fe034bf93d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_before_readmission(df, day_col, binary_col, cols_to_drop=[]):\n",
    "    # Create a variable to check if readmission is before the particular column by setting null values extremely high\n",
    "    days_to_readmission = df_clean['READMPODAYS1'].fillna(999)\n",
    "    df.loc[(days_to_readmission - df_clean[day_col])<=0, binary_col] = 0\n",
    "    dropcols = cols_to_drop + [day_col]\n",
    "    df.drop(columns=dropcols, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0cefa5fd-de7e-4f16-97c5-24cf2c1e667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dict = clean_dict['ensure_before_readmission']\n",
    "for binary_col in ensure_dict.keys():\n",
    "    df_clean = ensure_before_readmission(df_clean, ensure_dict[binary_col]['day_col'], binary_col, ensure_dict[binary_col]['cols_to_drop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "9731d052-5be2-4733-a45f-2326839214a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_df = pd.DataFrame(df_clean.columns)\n",
    "col_df.to_csv(\"columns.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0ac402-716e-4934-9a55-dba49e8c952b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
